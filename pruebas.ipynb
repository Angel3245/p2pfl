{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3333e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 54000 Val:6000 Test:10000\n",
      "INFO:root:Nodo a la escucha en 127.0.0.1 58735\n",
      "Train: 54000 Val:6000 Test:10000\n",
      "INFO:root:Nodo a la escucha en 127.0.0.1 50559\n",
      "INFO:root:(('127.0.0.1', 58735)) Conexi√≥n aceptada con ('127.0.0.1', 50559)\n",
      "INFO:root:(('127.0.0.1', 58735)) Broadcasting start learning...\n",
      "INFO:root:(('127.0.0.1', 58735)) Sending Initial Model Weights\n",
      "INFO:root:(('127.0.0.1', 58735)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(('127.0.0.1', 50559)) Broadcasting Number of Samples...\n",
      "INFO:root:(('127.0.0.1', 50559)) Initialicing Model Weights\n",
      "INFO:root:(('127.0.0.1', 50559)) Model initialized\n",
      "INFO:root:(('127.0.0.1', 58735)) Broadcasting Number of Samples...\n",
      "INFO:root:(('127.0.0.1', 58735)) Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bafe75a2f6324aba9d48b5284142126d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:(('127.0.0.1', 50559)) Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b1dbbeb3fe4453a95c768c5d152bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/.local/share/virtualenvs/federated_learning_p2p-ODhT9q3L/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric Accuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:(('127.0.0.1', 50559)) Evaluated. Losss: 2.301456928253174, Metric: 0.13089673221111298. (Check tensorboard for more info)\n",
      "INFO:root:(('127.0.0.1', 50559)) Broadcasting metrics to 1 clients.\n",
      "INFO:root:(('127.0.0.1', 50559)) Training...\n",
      "METRICS RECEIVED ('127.0.0.1:50559', 0, 2.301456928253174, 0.13089673221111298)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type     | Params\n",
      "------------------------------------\n",
      "0 | metric | Accuracy | 0     \n",
      "1 | l1     | Linear   | 100 K \n",
      "2 | l2     | Linear   | 33.0 K\n",
      "3 | l3     | Linear   | 2.6 K \n",
      "------------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n",
      "0.544     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d791786432024547bd61f70def41e50f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:(('127.0.0.1', 58735)) Evaluated. Losss: 2.301456928253174, Metric: 0.13286271691322327. (Check tensorboard for more info)\n",
      "INFO:root:(('127.0.0.1', 58735)) Broadcasting metrics to 1 clients.\n",
      "INFO:root:(('127.0.0.1', 58735)) Training...\n",
      "METRICS RECEIVED ('127.0.0.1:58735', 0, 2.301456928253174, 0.13286271691322327)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type     | Params\n",
      "------------------------------------\n",
      "0 | metric | Accuracy | 0     \n",
      "1 | l1     | Linear   | 100 K \n",
      "2 | l2     | Linear   | 33.0 K\n",
      "3 | l3     | Linear   | 2.6 K \n",
      "------------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n",
      "0.544     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0469ae0cc0e409a868deb7a7d2b7973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:(127.0.0.1:50559) Model added (1/2) from ('127.0.0.1', 50559)\n",
      "INFO:root:(('127.0.0.1', 50559)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(127.0.0.1:58735) Model added (1/2) from ('127.0.0.1', 50559)\n",
      "INFO:root:(127.0.0.1:58735) Model added (2/2) from ('127.0.0.1', 58735)\n",
      "INFO:root:(127.0.0.1:58735) Agregating models.\n",
      "INFO:root:(('127.0.0.1', 58735)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(('127.0.0.1', 58735)) Waiting other nodes.\n",
      "INFO:root:(127.0.0.1:50559) Model added (2/2) from ('127.0.0.1', 58735)\n",
      "INFO:root:(127.0.0.1:50559) Agregating models.\n",
      "INFO:root:(('127.0.0.1', 50559)) Waiting other nodes.\n",
      "INFO:root:(('127.0.0.1', 58735)) Round 1 of 2 finished.\n",
      "INFO:root:(('127.0.0.1', 50559)) Round 1 of 2 finished.\n",
      "INFO:root:(('127.0.0.1', 58735)) Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:(('127.0.0.1', 50559)) Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "GPU available: False, used: False\n",
      "IPU available: False, using: 0 IPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7556779c9944138a3ce94754b9d3e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37900061b5a3415cbfde3b725547ef67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:(('127.0.0.1', 58735)) Evaluated. Losss: 0.14684411883354187, Metric: 0.9332429766654968. (Check tensorboard for more info)\n",
      "INFO:root:(('127.0.0.1', 50559)) Evaluated. Losss: 0.14684411883354187, Metric: 0.9514185786247253. (Check tensorboard for more info)\n",
      "INFO:root:(('127.0.0.1', 58735)) Broadcasting metrics to 1 clients.\n",
      "INFO:root:(('127.0.0.1', 50559)) Broadcasting metrics to 1 clients.\n",
      "METRICS RECEIVED ('127.0.0.1:58735', 1, 0.14684411883354187, 0.9332429766654968)\n",
      "INFO:root:(('127.0.0.1', 58735)) Training...\n",
      "METRICS RECEIVED ('127.0.0.1:50559', 1, 0.14684411883354187, 0.9514185786247253)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:(('127.0.0.1', 50559)) Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "GPU available: False, used: False\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type     | Params\n",
      "------------------------------------\n",
      "0 | metric | Accuracy | 0     \n",
      "1 | l1     | Linear   | 100 K \n",
      "2 | l2     | Linear   | 33.0 K\n",
      "3 | l3     | Linear   | 2.6 K \n",
      "------------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n",
      "0.544     Total estimated model params size (MB)\n",
      "\n",
      "  | Name   | Type     | Params\n",
      "------------------------------------\n",
      "0 | metric | Accuracy | 0     \n",
      "1 | l1     | Linear   | 100 K \n",
      "2 | l2     | Linear   | 33.0 K\n",
      "3 | l3     | Linear   | 2.6 K \n",
      "------------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n",
      "0.544     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714e60ecaef84dd2868d5ff3a3394bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2e914949f448ee9f35c4242446997c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:(127.0.0.1:50559) Model added (1/2) from ('127.0.0.1', 50559)\n",
      "INFO:root:(('127.0.0.1', 50559)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(127.0.0.1:58735) Model added (1/2) from ('127.0.0.1', 58735)\n",
      "INFO:root:(('127.0.0.1', 58735)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(127.0.0.1:58735) Model added (2/2) from ('127.0.0.1', 50559)\n",
      "INFO:root:(127.0.0.1:58735) Agregating models.\n",
      "INFO:root:(127.0.0.1:50559) Model added (2/2) from ('127.0.0.1', 58735)\n",
      "INFO:root:(127.0.0.1:50559) Agregating models.\n",
      "INFO:root:(('127.0.0.1', 58735)) Waiting other nodes.\n",
      "INFO:root:(('127.0.0.1', 50559)) Waiting other nodes.\n",
      "INFO:root:(('127.0.0.1', 58735)) Round 2 of 2 finished.\n",
      "INFO:root:(('127.0.0.1', 50559)) Round 2 of 2 finished.\n",
      "INFO:root:(('127.0.0.1', 58735)) Evaluating...\n",
      "INFO:root:(('127.0.0.1', 50559)) Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "GPU available: False, used: False\n",
      "IPU available: False, using: 0 IPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f912f04ffc47b6b8e3d9cfdcb25a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7400438e8ad2432ea350b611a17c42cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:(('127.0.0.1', 58735)) Evaluated. Losss: 0.07988487929105759, Metric: 0.9446301460266113. (Check tensorboard for more info)\n",
      "INFO:root:(('127.0.0.1', 58735)) Broadcasting metrics to 1 clients.\n",
      "INFO:root:(('127.0.0.1', 58735)) Finish!!.\n",
      "METRICS RECEIVED ('127.0.0.1:58735', 2, 0.07988487929105759, 0.9446301460266113)\n",
      "INFO:root:(('127.0.0.1', 50559)) Evaluated. Losss: 0.07988487929105759, Metric: 0.958168625831604. (Check tensorboard for more info)\n",
      "INFO:root:(('127.0.0.1', 50559)) Broadcasting metrics to 1 clients.\n",
      "INFO:root:(('127.0.0.1', 50559)) Finish!!.\n",
      "METRICS RECEIVED ('127.0.0.1:50559', 2, 0.07988487929105759, 0.958168625831604)\n",
      "INFO:root:Bajando el nodo, dejando de escuchar en 127.0.0.1 58735 y desconect√°ndose de 1 nodos\n",
      "DEBUG:root:Closed connection: ('127.0.0.1', 58735)\n",
      "DEBUG:root:Closed connection: ('127.0.0.1', 50559)\n",
      "INFO:root:Bajando el nodo, dejando de escuchar en 127.0.0.1 50559 y desconect√°ndose de 0 nodos\n"
     ]
    }
   ],
   "source": [
    "from p2pfl.node import Node\n",
    "from p2pfl.learning.pytorch.mnist_examples.mnistfederated_dm import MnistFederatedDM\n",
    "from p2pfl.learning.pytorch.mnist_examples.models.mlp import MLP\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import time\n",
    "\n",
    "def test_convergence(x):\n",
    "    n,r = x\n",
    "\n",
    "    # Node Creation\n",
    "    nodes = []\n",
    "    for i in range(n):\n",
    "        node = Node(MLP(),MnistFederatedDM())\n",
    "        node.start()\n",
    "        nodes.append(node)\n",
    "\n",
    "    # Node Connection\n",
    "    for i in range(len(nodes)-1):\n",
    "        nodes[i+1].connect_to(nodes[i].host,nodes[i].port)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    # Check if they are connected\n",
    "    for node in nodes:\n",
    "        assert len(node.neightboors) == n-1\n",
    "\n",
    "    # Start Learning\n",
    "    nodes[0].set_start_learning(rounds=r,epochs=1)\n",
    "\n",
    "    # Wait 4 results\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "        finish = True\n",
    "        for f in [node.round is None for node in nodes]:\n",
    "            finish = finish and f\n",
    "\n",
    "        if finish:\n",
    "            break\n",
    "\n",
    "\n",
    "    # Validamos Modelos obtenidos sean iguales\n",
    "    model = None\n",
    "    first = True\n",
    "    for node in nodes:\n",
    "        if first:\n",
    "            model = node.learner.get_parameters()\n",
    "            first = False\n",
    "        else:\n",
    "            for layer in model:\n",
    "                a = torch.round(model[layer], decimals=2)\n",
    "                b = torch.round(node.learner.get_parameters()[layer], decimals=2)\n",
    "                assert torch.eq(a, b).all()\n",
    "\n",
    "    # Cerrar\n",
    "    for node in nodes:\n",
    "        node.stop()\n",
    "        time.sleep(.1) #Esperar por la asincron√≠a\n",
    "    \n",
    "    return nodes\n",
    "        \n",
    "nodes = test_convergence((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034fde84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from p2pfl.learning.pytorch.mnist_examples.mnistfederated_dm import MnistFederatedDM\n",
    "from p2pfl.learning.pytorch.mnist_examples.models.cnn import CNN\n",
    "from p2pfl.learning.pytorch.mnist_examples.models.mlp import MLP\n",
    "from p2pfl.node import Node\n",
    "import pytest\n",
    "import time\n",
    "import threading\n",
    "\n",
    "nodes = []\n",
    "        \n",
    "def test_node_down_on_learning(n):\n",
    "\n",
    "    # Node Creation\n",
    "    nodes = []\n",
    "    for i in range(n):\n",
    "        node = Node(MLP(),MnistFederatedDM())\n",
    "        node.start()\n",
    "        nodes.append(node)\n",
    "\n",
    "    # Node Connection\n",
    "    for i in range(len(nodes)-1):\n",
    "        nodes[i+1].connect_to(nodes[i].host,nodes[i].port)\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Check if they are connected\n",
    "    for node in nodes:\n",
    "        assert len(node.neightboors) == n-1\n",
    "\n",
    "    # Start Learning\n",
    "    nodes[0].set_start_learning(rounds=2,epochs=0)\n",
    "\n",
    "    # Stopping node\n",
    "    nodes[1].stop()\n",
    "    # Wait 4 results\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "        finish = True\n",
    "        for f in [node.round is None for node in nodes]:\n",
    "            finish = finish and f\n",
    "\n",
    "        if finish:\n",
    "            break\n",
    "\n",
    "    for node in nodes:\n",
    "        node.stop()\n",
    "\n",
    "\n",
    "nodes = []\n",
    "for _ in range(6):\n",
    "    test_node_down_on_learning(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d86781",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainThread\n",
      "IOPub\n",
      "Heartbeat\n",
      "Thread-3\n",
      "Thread-4\n",
      "Control\n",
      "IPythonHistorySavingThread\n",
      "Thread-2\n"
     ]
    }
   ],
   "source": [
    "#import threading\n",
    "for thread in threading.enumerate(): \n",
    "    print(thread.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "445e009c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/pedro/Documents/UDC/4/TFG/federated_learning_p2p/p2pfl/node.py',\n",
       " '__on_round_finished',\n",
       " 260)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def get_thread_position(thread):\n",
    "    frame = sys._current_frames().get(thread.ident, None)\n",
    "    if frame:\n",
    "        return frame.f_code.co_filename, frame.f_code.co_name, frame.f_code.co_firstlineno\n",
    "\n",
    "get_thread_position(threading.enumerate()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4471063f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainThread\n",
      "IOPub\n",
      "Heartbeat\n",
      "Thread-3\n",
      "Thread-4\n",
      "Control\n",
      "IPythonHistorySavingThread\n",
      "Thread-2\n",
      "Train: 54000 Val:6000 Test:10000\n",
      "Train: 54000 Val:6000 Test:10000\n",
      "\n",
      "\n",
      "INFO:root:Nodo a la escucha en 127.0.0.1 54998\n",
      "INFO:root:Nodo a la escucha en 127.0.0.1 54999\n",
      "INFO:root:(('127.0.0.1', 54999)) Conexi√≥n aceptada con ('127.0.0.1', 54998)\n",
      "INFO:root:(('127.0.0.1', 54998)) Broadcasting start learning...\n",
      "INFO:root:(('127.0.0.1', 54998)) Sending Initial Model Weights\n",
      "INFO:root:(('127.0.0.1', 54999)) Initialicing Model Weights\n",
      "INFO:root:(('127.0.0.1', 54998)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(('127.0.0.1', 54998)) Broadcasting Number of Samples...\n",
      "INFO:root:(('127.0.0.1', 54998)) Training...\n",
      "INFO:root:(('127.0.0.1', 54999)) Model initialized\n",
      "INFO:root:(('127.0.0.1', 54998)) Model added (1/2) from ('127.0.0.1', 54998)\n",
      "INFO:root:(('127.0.0.1', 54998)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(('127.0.0.1', 54999)) Model added (1/2) from ('127.0.0.1', 54998)\n",
      "INFO:root:(('127.0.0.1', 54999)) Broadcasting Number of Samples...\n",
      "INFO:root:(('127.0.0.1', 54999)) Training...\n",
      "INFO:root:(('127.0.0.1', 54999)) Model added (2/2) from ('127.0.0.1', 54999)\n",
      "INFO:root:(('127.0.0.1', 54999)) Agregating models.\n",
      "INFO:root:(('127.0.0.1', 54999)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(('127.0.0.1', 54999)) Waiting other nodes.\n",
      "ERROR:root:(('127.0.0.1', 54998)) Error decoding parameters\n",
      "INFO:root:(('127.0.0.1', 54998)) Stopping learning\n",
      "INFO:root:Bajando el nodo, dejando de escuchar en 127.0.0.1 54998 y desconect√°ndose de 1 nodos\n",
      "DEBUG:root:Closed connection: ('127.0.0.1', 54998)\n",
      "DEBUG:root:Closed connection: ('127.0.0.1', 54999)\n",
      "INFO:root:(('127.0.0.1', 54999)) Stopping learning\n",
      "INFO:root:Bajando el nodo, dejando de escuchar en 127.0.0.1 54999 y desconect√°ndose de 0 nodos\n",
      "MainThread\n",
      "IOPub\n",
      "Heartbeat\n",
      "Thread-3\n",
      "Thread-4\n",
      "Control\n",
      "IPythonHistorySavingThread\n",
      "Thread-2\n",
      "heartbeater-127.0.0.1:54999\n",
      "node-127.0.0.1:54999\n",
      "learning_thread-127.0.0.1:54999\n",
      "learning_thread-127.0.0.1:54998\n",
      "agregator-127.0.0.1:54998\n",
      "\n",
      "\n",
      "INFO:root:(('127.0.0.1', 54999)) Stopping on_round_finished process.\n"
     ]
    }
   ],
   "source": [
    "from p2pfl.const import HEARTBEAT_FREC, SOCKET_TIEMOUT\n",
    "from p2pfl.learning.pytorch.mnist_examples.mnistfederated_dm import MnistFederatedDM\n",
    "from p2pfl.learning.pytorch.mnist_examples.models.cnn import CNN\n",
    "from p2pfl.learning.pytorch.mnist_examples.models.mlp import MLP\n",
    "from p2pfl.node import Node\n",
    "import pytest\n",
    "import time\n",
    "from test.fixtures import two_nodes, four_nodes\n",
    "\n",
    "\n",
    "import threading\n",
    "for thread in threading.enumerate(): \n",
    "    print(thread.name)\n",
    "    \n",
    "n1 = Node(MLP(),MnistFederatedDM())\n",
    "n2 = Node(MLP(),MnistFederatedDM())\n",
    "print(\"\\n\")\n",
    "def test_bad_binary_model():\n",
    "\n",
    "    n1.start()\n",
    "    n2.start()\n",
    "\n",
    "    n1.connect_to(n2.host,n2.port)\n",
    "    time.sleep(0.1) \n",
    "\n",
    "    # Start Learning\n",
    "    n1.set_start_learning(rounds=2,epochs=0)\n",
    " \n",
    "    # Adding noise to the buffer\n",
    "    for _ in range(200):\n",
    "        n1.neightboors[0].param_bufffer += \"noise\".encode(\"utf-8\")\n",
    "    \n",
    "    while not n1.round is None and not n2.round is None:\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "    n1.stop()\n",
    "    n2.stop()\n",
    "    \n",
    "test_bad_binary_model()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "for thread in threading.enumerate(): \n",
    "    print(thread.name)\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7fe91dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainThread\n",
      "IOPub\n",
      "Heartbeat\n",
      "Thread-3\n",
      "Thread-4\n",
      "Control\n",
      "IPythonHistorySavingThread\n",
      "Thread-2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for thread in threading.enumerate(): \n",
    "    print(thread.name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aec30564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(n1.round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc69eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from p2pfl.settings import Settings\n",
    "\n",
    "Settings.AGREGATION_TIEMOUT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccd4109a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"0.1545318067073822\".isdecimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cfda0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.301456928253174 0.13700607419013977\n"
     ]
    }
   ],
   "source": [
    "message = ['METRICS', '0', '2.301456928253174', '0.13700607419013977']\n",
    "print(int(message[1]), float(message[2]), float(message[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98edc3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
