{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3333e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /var/folders/vm/p9lv42ms7ml71cjvsj4bnbnm0000gn/T/tmpwb3qaumo\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /var/folders/vm/p9lv42ms7ml71cjvsj4bnbnm0000gn/T/tmpwb3qaumo/_remote_module_non_sriptable.py\n",
      "INFO:root:Nodo a la escucha en localhost 56332\n",
      "INFO:root:Nodo a la escucha en localhost 56333\n",
      "INFO:root:Conexión aceptada con ('localhost', 56333)\n",
      "INFO:root:Broadcasting start learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.12/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "Exception in thread Thread-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.12/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.12/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pedro/Documents/UDC/4/TFG/federated_learning_p2p/p2pfl/node.py\", line 247, in start_learning\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.12/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pedro/Documents/UDC/4/TFG/federated_learning_p2p/p2pfl/node.py\", line 247, in start_learning\n",
      "    self.broadcast(CommunicationProtocol.build_num_samples_msg(self.learner.get_num_samples()))\n",
      "  File \"/Users/pedro/Documents/UDC/4/TFG/federated_learning_p2p/p2pfl/learning/pytorch/learners/lightninglearner.py\", line 71, in get_num_samples\n",
      "    self.broadcast(CommunicationProtocol.build_num_samples_msg(self.learner.get_num_samples()))\n",
      "  File \"/Users/pedro/Documents/UDC/4/TFG/federated_learning_p2p/p2pfl/learning/pytorch/learners/lightninglearner.py\", line 71, in get_num_samples\n",
      "    return len(self.data.train_dataloader().dataset)\n",
      "  File \"/Users/pedro/Documents/UDC/4/TFG/federated_learning_p2p/p2pfl/learning/pytorch/datamodules/mnist.py\", line 47, in train_dataloader\n",
      "    return len(self.data.train_dataloader().dataset)\n",
      "  File \"/Users/pedro/Documents/UDC/4/TFG/federated_learning_p2p/p2pfl/learning/pytorch/datamodules/mnist.py\", line 47, in train_dataloader\n",
      "    return self.train_loader\n",
      "AttributeError: 'MnistFederatedDM' object has no attribute 'train_loader'\n",
      "    return self.train_loader\n",
      "AttributeError: 'MnistFederatedDM' object has no attribute 'train_loader'\n"
     ]
    }
   ],
   "source": [
    "from p2pfl.node import Node\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "def test_convergence(x):\n",
    "    n,r = x\n",
    "\n",
    "    # Node Creation\n",
    "    nodes = []\n",
    "    for i in range(n):\n",
    "        node = Node(host=\"localhost\")\n",
    "        node.start()\n",
    "        nodes.append(node)\n",
    "\n",
    "    # Node Connection\n",
    "    for i in range(len(nodes)-1):\n",
    "        nodes[i+1].connect_to(nodes[i].host,nodes[i].port)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    # Check if they are connected\n",
    "    for node in nodes:\n",
    "        assert len(node.neightboors) == n-1\n",
    "\n",
    "    # Start Learning\n",
    "    nodes[0].set_start_learning(rounds=r,epochs=0)\n",
    "\n",
    "    # Wait 4 results\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "        finish = True\n",
    "        for f in [node.round is None for node in nodes]:\n",
    "            finish = finish and f\n",
    "\n",
    "        if finish:\n",
    "            break\n",
    "\n",
    "\n",
    "    # Validamos Modelos obtenidos sean iguales\n",
    "    model = None\n",
    "    first = True\n",
    "    for node in nodes:\n",
    "        if first:\n",
    "            model = node.learner.get_parameters()\n",
    "            first = False\n",
    "        else:\n",
    "            for layer in model:\n",
    "                a = torch.round(model[layer], decimals=2)\n",
    "                b = torch.round(node.learner.get_parameters()[layer], decimals=2)\n",
    "                assert torch.eq(a, b).all()\n",
    "\n",
    "    # Cerrar\n",
    "    for node in nodes:\n",
    "        node.stop()\n",
    "        time.sleep(.1) #Esperar por la asincronía\n",
    "\n",
    "        \n",
    "test_convergence((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23e00247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Nodo a la escucha en localhost 65058\n",
      "INFO:root:Nodo a la escucha en localhost 65059\n",
      "INFO:root:Conexión aceptada con ('localhost', 65058)\n",
      "INFO:root:Broadcasting start learning...\n",
      "INFO:root:Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type     | Params\n",
      "--------------------------------------\n",
      "0 | accuracy | Accuracy | 0     \n",
      "1 | l1       | Linear   | 100 K \n",
      "2 | l2       | Linear   | 33.0 K\n",
      "3 | l3       | Linear   | 2.6 K \n",
      "--------------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n",
      "0.544     Total estimated model params size (MB)\n",
      "\n",
      "  | Name     | Type     | Params\n",
      "--------------------------------------\n",
      "0 | accuracy | Accuracy | 0     \n",
      "1 | l1       | Linear   | 100 K \n",
      "2 | l2       | Linear   | 33.0 K\n",
      "3 | l3       | Linear   | 2.6 K \n",
      "--------------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n",
      "0.544     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 54000 Val:6000 Test:10000Train: 54000 Val:6000 Test:10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Stopping learning\n",
      "INFO:root:Stopping learning\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from p2pfl.const import HEARTBEAT_FREC, TIEMOUT\n",
    "from p2pfl.node import Node\n",
    "import time\n",
    "\n",
    "n1 = Node(\"localhost\")\n",
    "n2 = Node(\"localhost\")\n",
    "n1.start()\n",
    "n2.start()\n",
    "\n",
    "def test_interrupt_train2(two_nodes):\n",
    "    n1, n2 = two_nodes\n",
    "    n1.connect_to(n2.host,n2.port)\n",
    "\n",
    "    time.sleep(1) #Esperar por la asincronía\n",
    "\n",
    "    n1.set_start_learning(99999,99999)\n",
    "\n",
    "    time.sleep(1) #Esperar por la asincronía\n",
    "\n",
    "    n2.set_stop_learning()\n",
    "    \n",
    "    time.sleep(1) #Esperar por la asincronía\n",
    "    \n",
    "    print(n1.round)\n",
    "    print(n2.round)\n",
    "    \n",
    "    assert n1.round is None\n",
    "    \n",
    "test_interrupt_train2((n1,n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d7ffdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Nodo a la escucha en localhost 53709\n",
      "OrderedDict([('l1.weight', tensor([[-0.0287, -0.0048,  0.0294,  ..., -0.0250,  0.0217,  0.0113],\n",
      "        [ 0.0220,  0.0061, -0.0328,  ...,  0.0185, -0.0317,  0.0078],\n",
      "        [-0.0262,  0.0216, -0.0159,  ...,  0.0109, -0.0086, -0.0018],\n",
      "        ...,\n",
      "        [-0.0180, -0.0295, -0.0029,  ...,  0.0145,  0.0264, -0.0134],\n",
      "        [-0.0250,  0.0020,  0.0125,  ..., -0.0091, -0.0146,  0.0017],\n",
      "        [-0.0181,  0.0163, -0.0033,  ..., -0.0196,  0.0291, -0.0250]])), ('l1.bias', tensor([-0.0087, -0.0157,  0.0090, -0.0334, -0.0151,  0.0152, -0.0332, -0.0143,\n",
      "         0.0033, -0.0339,  0.0156, -0.0132,  0.0216, -0.0017,  0.0076,  0.0226,\n",
      "         0.0004,  0.0032, -0.0017,  0.0002,  0.0179,  0.0308, -0.0074,  0.0035,\n",
      "         0.0149,  0.0118,  0.0151, -0.0157, -0.0181, -0.0106,  0.0268, -0.0154,\n",
      "        -0.0269,  0.0259,  0.0116, -0.0209,  0.0097,  0.0323,  0.0036, -0.0121,\n",
      "        -0.0157, -0.0216,  0.0324,  0.0271, -0.0292,  0.0356,  0.0192,  0.0357,\n",
      "         0.0250, -0.0183, -0.0025, -0.0343,  0.0144, -0.0058,  0.0088, -0.0180,\n",
      "        -0.0217, -0.0084, -0.0047, -0.0249, -0.0031, -0.0024, -0.0213,  0.0057,\n",
      "         0.0326, -0.0215,  0.0229,  0.0270,  0.0314,  0.0310,  0.0353, -0.0107,\n",
      "        -0.0252,  0.0064,  0.0095, -0.0295,  0.0255, -0.0097, -0.0333, -0.0136,\n",
      "        -0.0295,  0.0246,  0.0283, -0.0032, -0.0017,  0.0069,  0.0230,  0.0278,\n",
      "        -0.0112, -0.0228, -0.0099, -0.0181, -0.0210, -0.0009, -0.0109, -0.0145,\n",
      "         0.0133, -0.0017, -0.0090,  0.0009, -0.0266,  0.0330,  0.0265, -0.0060,\n",
      "        -0.0350, -0.0177, -0.0112, -0.0002, -0.0171, -0.0211,  0.0012,  0.0211,\n",
      "        -0.0110, -0.0282, -0.0171,  0.0286, -0.0276,  0.0110,  0.0336, -0.0158,\n",
      "         0.0297,  0.0264, -0.0333, -0.0084,  0.0205,  0.0111,  0.0076, -0.0244])), ('l2.weight', tensor([[ 0.0528, -0.0426,  0.0759,  ..., -0.0679,  0.0734,  0.0450],\n",
      "        [-0.0340,  0.0768, -0.0836,  ...,  0.0598, -0.0156, -0.0557],\n",
      "        [ 0.0021, -0.0322,  0.0393,  ...,  0.0431, -0.0057, -0.0065],\n",
      "        ...,\n",
      "        [ 0.0205,  0.0151, -0.0709,  ..., -0.0795, -0.0065,  0.0611],\n",
      "        [-0.0806, -0.0784, -0.0759,  ...,  0.0702, -0.0039,  0.0653],\n",
      "        [-0.0503,  0.0685,  0.0238,  ..., -0.0409, -0.0013,  0.0731]])), ('l2.bias', tensor([ 0.0873,  0.0489,  0.0866,  0.0591,  0.0316, -0.0387, -0.0188, -0.0387,\n",
      "        -0.0108, -0.0092,  0.0277,  0.0500, -0.0046,  0.0271,  0.0672, -0.0577,\n",
      "         0.0815, -0.0419, -0.0607, -0.0842, -0.0881, -0.0254, -0.0211, -0.0452,\n",
      "        -0.0489, -0.0182, -0.0625,  0.0469, -0.0500,  0.0248,  0.0491, -0.0197,\n",
      "        -0.0657,  0.0096, -0.0022, -0.0328, -0.0195, -0.0027, -0.0219, -0.0804,\n",
      "         0.0535, -0.0502,  0.0185, -0.0784,  0.0137, -0.0740,  0.0591, -0.0830,\n",
      "        -0.0623,  0.0220, -0.0357,  0.0710,  0.0289, -0.0397, -0.0140, -0.0178,\n",
      "         0.0355,  0.0739, -0.0498, -0.0800, -0.0049, -0.0347,  0.0698,  0.0822,\n",
      "        -0.0280,  0.0745, -0.0514, -0.0746, -0.0454, -0.0556,  0.0326, -0.0566,\n",
      "         0.0226,  0.0260, -0.0082,  0.0327, -0.0435, -0.0884, -0.0726, -0.0810,\n",
      "        -0.0113,  0.0229, -0.0468,  0.0821, -0.0222, -0.0786,  0.0482,  0.0517,\n",
      "         0.0383,  0.0086, -0.0721,  0.0746, -0.0384, -0.0818,  0.0151,  0.0722,\n",
      "        -0.0078,  0.0473,  0.0006, -0.0709, -0.0351,  0.0430,  0.0630,  0.0624,\n",
      "        -0.0130,  0.0379,  0.0463,  0.0340, -0.0629, -0.0207,  0.0169, -0.0500,\n",
      "        -0.0359,  0.0215,  0.0065, -0.0068,  0.0042, -0.0013,  0.0009,  0.0382,\n",
      "        -0.0801, -0.0030, -0.0827, -0.0497,  0.0473, -0.0760, -0.0413, -0.0770,\n",
      "         0.0337, -0.0179, -0.0012,  0.0704,  0.0187, -0.0575,  0.0548,  0.0329,\n",
      "        -0.0184, -0.0603, -0.0097,  0.0486,  0.0311,  0.0224, -0.0860, -0.0861,\n",
      "        -0.0770,  0.0746,  0.0265, -0.0754, -0.0057, -0.0872, -0.0747, -0.0098,\n",
      "         0.0692,  0.0032, -0.0156,  0.0188, -0.0286, -0.0051,  0.0074, -0.0869,\n",
      "        -0.0377,  0.0655, -0.0365, -0.0247,  0.0043, -0.0109, -0.0516,  0.0567,\n",
      "         0.0043, -0.0362, -0.0200,  0.0416,  0.0285, -0.0289, -0.0029, -0.0348,\n",
      "         0.0303, -0.0735, -0.0547,  0.0846, -0.0721, -0.0854,  0.0038, -0.0516,\n",
      "         0.0329, -0.0228,  0.0710,  0.0837,  0.0486,  0.0773, -0.0188,  0.0015,\n",
      "         0.0734,  0.0123,  0.0362, -0.0050,  0.0867,  0.0209,  0.0260, -0.0201,\n",
      "         0.0319,  0.0423, -0.0152,  0.0477, -0.0254,  0.0667,  0.0694,  0.0037,\n",
      "        -0.0225, -0.0113,  0.0189,  0.0199,  0.0556, -0.0417, -0.0116,  0.0106,\n",
      "         0.0015, -0.0026, -0.0216,  0.0758,  0.0079, -0.0055, -0.0302, -0.0064,\n",
      "        -0.0213,  0.0815,  0.0114,  0.0070, -0.0710,  0.0151,  0.0660, -0.0211,\n",
      "         0.0786, -0.0659, -0.0510,  0.0204, -0.0822,  0.0037, -0.0281, -0.0710,\n",
      "         0.0718, -0.0218,  0.0161, -0.0789, -0.0600, -0.0137, -0.0822, -0.0290,\n",
      "        -0.0734, -0.0471, -0.0694,  0.0477, -0.0108, -0.0451, -0.0845,  0.0464])), ('l3.weight', tensor([[-0.0286, -0.0398, -0.0606,  ...,  0.0190, -0.0017, -0.0394],\n",
      "        [-0.0169,  0.0009, -0.0048,  ..., -0.0042,  0.0389,  0.0205],\n",
      "        [-0.0486,  0.0090, -0.0142,  ...,  0.0253, -0.0267,  0.0582],\n",
      "        ...,\n",
      "        [-0.0392,  0.0480, -0.0086,  ...,  0.0332, -0.0363,  0.0355],\n",
      "        [ 0.0525,  0.0544,  0.0351,  ..., -0.0398, -0.0594, -0.0581],\n",
      "        [-0.0562,  0.0397,  0.0037,  ...,  0.0145, -0.0353,  0.0081]])), ('l3.bias', tensor([ 0.0591,  0.0090, -0.0060, -0.0470, -0.0010, -0.0345,  0.0387, -0.0094,\n",
      "        -0.0166,  0.0320]))])\n"
     ]
    }
   ],
   "source": [
    "from p2pfl.node import Node\n",
    "import torch\n",
    "\n",
    "n1 = Node(\"localhost\")\n",
    "n1.start()\n",
    "\n",
    "sum = n1.learner.get_parameters()\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f35e9842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "sum = [torch.zeros_like(sum[layer]) for layer in sum]\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fc66a1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from p2pfl.learning.agregators.fedavg import FedAvg\n",
    "from p2pfl.learning.pytorch.models.mlp import MLP\n",
    "from p2pfl.learning.pytorch.learners.lightninglearner import LightningLearner\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def test_avg_simple():\n",
    "\n",
    "    a = OrderedDict([('a', torch.tensor(-1)), ('b', torch.tensor(-1))])\n",
    "    b = OrderedDict([('a', torch.tensor(0)), ('b', torch.tensor(0))])\n",
    "    c = OrderedDict([('a', torch.tensor(1)), ('b', torch.tensor(1))])\n",
    "\n",
    "    result = FedAvg.agregate([(a,1),(b,1),(c,1)])\n",
    "\n",
    "    for layer in b:\n",
    "        assert result[layer] == b[layer]\n",
    "        \n",
    "test_avg_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee5cd38",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39meq(a, b)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[43mtest_avg_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mtest_avg_complex\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     params1[layer] \u001b[38;5;241m=\u001b[39m params1[layer]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     22\u001b[0m     params2[layer] \u001b[38;5;241m=\u001b[39m params2[layer]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 24\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mFedAvg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams1\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams2\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Check Results\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m params:\n",
      "File \u001b[0;32m~/Documents/UDC/4/TFG/federated_learning_p2p/p2pfl/learning/agregators/fedavg.py:50\u001b[0m, in \u001b[0;36mFedAvg.agregate\u001b[0;34m(models)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m,w \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m m:\n\u001b[0;32m---> 50\u001b[0m         accum[layer] \u001b[38;5;241m=\u001b[39m \u001b[43maccum\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mw\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Normalize Accum\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m accum:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from p2pfl.learning.agregators.fedavg import FedAvg\n",
    "from p2pfl.learning.pytorch.models.mlp import MLP\n",
    "from p2pfl.learning.pytorch.learners.lightninglearner import LightningLearner\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "\n",
    "\n",
    "def test_avg_complex():\n",
    "    nl1 = LightningLearner(MLP(), None)\n",
    "    params = nl1.get_parameters()\n",
    "    params1 = nl1.get_parameters()\n",
    "    params2 = nl1.get_parameters()\n",
    "\n",
    "    result = FedAvg.agregate([(params,1)])\n",
    "\n",
    "    # Check Results\n",
    "    for layer in params:\n",
    "        assert torch.eq(params[layer], result[layer]).all()\n",
    "\n",
    "    for layer in params2:\n",
    "        params1[layer] = params1[layer]+1\n",
    "        params2[layer] = params2[layer]-1\n",
    "    \n",
    "    result = FedAvg.agregate([(params1,1), (params2,1)])\n",
    "\n",
    "    # Check Results\n",
    "    for layer in params:\n",
    "        a = torch.trunc(params[layer]*10)\n",
    "        b = torch.trunc(result[layer]*10)\n",
    "        assert torch.eq(a, b).all()\n",
    "        \n",
    "while True:\n",
    "    test_avg_complex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "758ef836",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2964970389.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [3]\u001b[0;36m\u001b[0m\n\u001b[0;31m    1.shape()\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c81d0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from p2pfl.node import Node\n",
    "\n",
    "\n",
    "n1 = Node(\"localhost\")\n",
    "n1.start()\n",
    "\n",
    "n1.learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf4185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
