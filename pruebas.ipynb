{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3333e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /var/folders/vm/p9lv42ms7ml71cjvsj4bnbnm0000gn/T/tmpimz5oumh\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /var/folders/vm/p9lv42ms7ml71cjvsj4bnbnm0000gn/T/tmpimz5oumh/_remote_module_non_sriptable.py\n",
      "Train: 54000 Val:6000 Test:10000\n",
      "INFO:root:Nodo a la escucha en localhost 51409\n",
      "Train: 54000 Val:6000 Test:10000\n",
      "INFO:root:Nodo a la escucha en localhost 51410\n",
      "INFO:root:Conexión aceptada con ('localhost', 51410)\n",
      "INFO:root:Broadcasting start learning...\n",
      "INFO:root:Training...\n",
      "INFO:root:Training...\n",
      "INFO:root:Model added (1/2)\n",
      "INFO:root:Model added (1/2)\n",
      "INFO:root:Broadcasting model to all clients...\n",
      "INFO:root:Broadcasting model to all clients...\n",
      "INFO:root:Model added (2/2)\n",
      "INFO:root:Agregating models.\n",
      "[54000, 54000]\n",
      "INFO:root:Round 1 of 2 finished. (('localhost', 51410))\n",
      "INFO:root:Training...\n",
      "INFO:root:Model added (2/2)\n",
      "INFO:root:Model added (1/2)\n",
      "INFO:root:Broadcasting model to all clients...\n",
      "INFO:root:Agregating models.\n",
      "[54000, 54000]\n",
      "INFO:root:Round 1 of 2 finished. (('localhost', 51409))\n",
      "INFO:root:Training...\n",
      "INFO:root:Model added (1/2)\n",
      "INFO:root:Broadcasting model to all clients...\n",
      "INFO:root:Model added (2/2)\n",
      "INFO:root:Agregating models.\n",
      "[54000, 54000]\n",
      "INFO:root:Model added (2/2)\n",
      "INFO:root:Round 2 of 2 finished. (('localhost', 51409))\n",
      "INFO:root:Agregating models.\n",
      "[54000, 54000]\n",
      "INFO:root:Finish!!.\n",
      "INFO:root:Round 2 of 2 finished. (('localhost', 51410))\n",
      "INFO:root:Finish!!.\n",
      "INFO:root:Bajando el nodo, dejando de escuchar en localhost 51409\n",
      "DEBUG:root:Closed connection: ('localhost', 51409)\n",
      "DEBUG:root:Closed connection: ('localhost', 51410)\n",
      "INFO:root:Bajando el nodo, dejando de escuchar en localhost 51410\n"
     ]
    }
   ],
   "source": [
    "from p2pfl.node import Node\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "def test_convergence(x):\n",
    "    n,r = x\n",
    "\n",
    "    # Node Creation\n",
    "    nodes = []\n",
    "    for i in range(n):\n",
    "        node = Node(host=\"localhost\")\n",
    "        node.start()\n",
    "        nodes.append(node)\n",
    "\n",
    "    # Node Connection\n",
    "    for i in range(len(nodes)-1):\n",
    "        nodes[i+1].connect_to(nodes[i].host,nodes[i].port)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    # Check if they are connected\n",
    "    for node in nodes:\n",
    "        assert len(node.neightboors) == n-1\n",
    "\n",
    "    # Start Learning\n",
    "    nodes[0].set_start_learning(rounds=r,epochs=0)\n",
    "\n",
    "    # Wait 4 results\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "        finish = True\n",
    "        for f in [node.round is None for node in nodes]:\n",
    "            finish = finish and f\n",
    "\n",
    "        if finish:\n",
    "            break\n",
    "\n",
    "\n",
    "    # Validamos Modelos obtenidos sean iguales\n",
    "    model = None\n",
    "    first = True\n",
    "    for node in nodes:\n",
    "        if first:\n",
    "            model = node.learner.get_parameters()\n",
    "            first = False\n",
    "        else:\n",
    "            for layer in model:\n",
    "                a = torch.round(model[layer], decimals=2)\n",
    "                b = torch.round(node.learner.get_parameters()[layer], decimals=2)\n",
    "                assert torch.eq(a, b).all()\n",
    "\n",
    "    # Cerrar\n",
    "    for node in nodes:\n",
    "        node.stop()\n",
    "        time.sleep(.1) #Esperar por la asincronía\n",
    "\n",
    "        \n",
    "test_convergence((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23e00247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '_tkinter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mp2pfl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconst\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HEARTBEAT_FREC, TIEMOUT\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mp2pfl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Node\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      5\u001b[0m n1 \u001b[38;5;241m=\u001b[39m Node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/UDC/4/TFG/federated_learning_p2p/p2pfl/node.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mp2pfl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlearning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlearners\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlightninglearner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningLearner\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mp2pfl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlearning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmlp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MLP\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mp2pfl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnode_connection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NodeConnection\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mp2pfl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mheartbeater\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Heartbeater\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/UDC/4/TFG/federated_learning_p2p/p2pfl/node_connection.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtkinter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m E\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mp2pfl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommand\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mp2pfl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommunication_protocol\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CommunicationProtocol\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.12/Frameworks/Python.framework/Versions/3.9/lib/python3.9/tkinter/__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01m_tkinter\u001b[39;00m \u001b[38;5;66;03m# If this fails your Python may not be configured for Tk\u001b[39;00m\n\u001b[1;32m     38\u001b[0m TclError \u001b[38;5;241m=\u001b[39m _tkinter\u001b[38;5;241m.\u001b[39mTclError\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtkinter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '_tkinter'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d7ffdf5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agregate() missing 1 required positional argument: 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtrunc(result[layer]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39meq(a, b)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m---> 31\u001b[0m \u001b[43mtest_avg_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mtest_avg_complex\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     params1[layer] \u001b[38;5;241m=\u001b[39m params1[layer]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     21\u001b[0m     params2[layer] \u001b[38;5;241m=\u001b[39m params2[layer]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 23\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mFedAvg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams1\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams2\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Check Results -> Careful with rounding errors\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m params:\n",
      "\u001b[0;31mTypeError\u001b[0m: agregate() missing 1 required positional argument: 'models'"
     ]
    }
   ],
   "source": [
    "from p2pfl.learning.agregators.fedavg import FedAvg\n",
    "from p2pfl.learning.pytorch.models.mlp import MLP\n",
    "from p2pfl.learning.pytorch.learners.lightninglearner import LightningLearner\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "def test_avg_complex():\n",
    "    agregator = FedAvg(None)\n",
    "    nl1 = LightningLearner(MLP(), None)\n",
    "    params = nl1.get_parameters()\n",
    "    params1 = nl1.get_parameters()\n",
    "    params2 = nl1.get_parameters()\n",
    "\n",
    "    result = agregator.agregate([(params,1)])\n",
    "\n",
    "    # Check Results\n",
    "    for layer in params:\n",
    "        assert torch.eq(params[layer], result[layer]).all()\n",
    "\n",
    "    for layer in params2:\n",
    "        params1[layer] = params1[layer]+1\n",
    "        params2[layer] = params2[layer]-1\n",
    "    \n",
    "    result = FedAvg.agregate([(params1,1), (params2,1)])\n",
    "\n",
    "    # Check Results -> Careful with rounding errors\n",
    "    for layer in params:\n",
    "        a = torch.trunc(params[layer]*10)\n",
    "        b = torch.trunc(result[layer]*10)\n",
    "        assert torch.eq(a, b).all()\n",
    "\n",
    "test_avg_complex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f35e9842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "sum = [torch.zeros_like(sum[layer]) for layer in sum]\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fc66a1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from p2pfl.learning.agregators.fedavg import FedAvg\n",
    "from p2pfl.learning.pytorch.models.mlp import MLP\n",
    "from p2pfl.learning.pytorch.learners.lightninglearner import LightningLearner\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def test_avg_simple():\n",
    "\n",
    "    a = OrderedDict([('a', torch.tensor(-1)), ('b', torch.tensor(-1))])\n",
    "    b = OrderedDict([('a', torch.tensor(0)), ('b', torch.tensor(0))])\n",
    "    c = OrderedDict([('a', torch.tensor(1)), ('b', torch.tensor(1))])\n",
    "\n",
    "    result = FedAvg.agregate([(a,1),(b,1),(c,1)])\n",
    "\n",
    "    for layer in b:\n",
    "        assert result[layer] == b[layer]\n",
    "        \n",
    "test_avg_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee5cd38",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39meq(a, b)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[43mtest_avg_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mtest_avg_complex\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     params1[layer] \u001b[38;5;241m=\u001b[39m params1[layer]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     22\u001b[0m     params2[layer] \u001b[38;5;241m=\u001b[39m params2[layer]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 24\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mFedAvg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams1\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams2\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Check Results\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m params:\n",
      "File \u001b[0;32m~/Documents/UDC/4/TFG/federated_learning_p2p/p2pfl/learning/agregators/fedavg.py:50\u001b[0m, in \u001b[0;36mFedAvg.agregate\u001b[0;34m(models)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m,w \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m m:\n\u001b[0;32m---> 50\u001b[0m         accum[layer] \u001b[38;5;241m=\u001b[39m \u001b[43maccum\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mw\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Normalize Accum\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m accum:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from p2pfl.learning.agregators.fedavg import FedAvg\n",
    "from p2pfl.learning.pytorch.models.mlp import MLP\n",
    "from p2pfl.learning.pytorch.learners.lightninglearner import LightningLearner\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "\n",
    "\n",
    "def test_avg_complex():\n",
    "    nl1 = LightningLearner(MLP(), None)\n",
    "    params = nl1.get_parameters()\n",
    "    params1 = nl1.get_parameters()\n",
    "    params2 = nl1.get_parameters()\n",
    "\n",
    "    result = FedAvg.agregate([(params,1)])\n",
    "\n",
    "    # Check Results\n",
    "    for layer in params:\n",
    "        assert torch.eq(params[layer], result[layer]).all()\n",
    "\n",
    "    for layer in params2:\n",
    "        params1[layer] = params1[layer]+1\n",
    "        params2[layer] = params2[layer]-1\n",
    "    \n",
    "    result = FedAvg.agregate([(params1,1), (params2,1)])\n",
    "\n",
    "    # Check Results\n",
    "    for layer in params:\n",
    "        a = torch.trunc(params[layer]*10)\n",
    "        b = torch.trunc(result[layer]*10)\n",
    "        assert torch.eq(a, b).all()\n",
    "        \n",
    "while True:\n",
    "    test_avg_complex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "758ef836",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2964970389.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [3]\u001b[0;36m\u001b[0m\n\u001b[0;31m    1.shape()\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c81d0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from p2pfl.node import Node\n",
    "\n",
    "\n",
    "n1 = Node(\"localhost\")\n",
    "n1.start()\n",
    "\n",
    "n1.learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2faf4185",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'all'"
     ]
    }
   ],
   "source": [
    "[True].all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d5704f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'c']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def myFun(a,*argv): \n",
    "    for arg in argv: \n",
    "        print (arg)\n",
    "\n",
    "[myFun(cmd,args) for cmd,args in [(\"a\",[\"b\",\"c\"])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08adc39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /var/folders/vm/p9lv42ms7ml71cjvsj4bnbnm0000gn/T/tmp8lxoxgoo\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /var/folders/vm/p9lv42ms7ml71cjvsj4bnbnm0000gn/T/tmp8lxoxgoo/_remote_module_non_sriptable.py\n",
      "Train: 54000 Val:6000 Test:10000\n",
      "Train: 54000 Val:6000 Test:10000\n",
      "INFO:root:Nodo a la escucha en localhost 51091\n",
      "INFO:root:Nodo a la escucha en localhost 51092\n",
      "INFO:root:Conexión aceptada con ('localhost', 51091)\n",
      "1\n",
      "DEBUG:root:Too mucho errors. ('localhost', 51091)\n",
      "DEBUG:root:Last error: b'saludos Enrique y Dani'\n",
      "DEBUG:root:Closed connection: ('localhost', 51091)\n"
     ]
    }
   ],
   "source": [
    "from p2pfl.const import HEARTBEAT_FREC, TIEMOUT\n",
    "from p2pfl.node import Node\n",
    "import time\n",
    "\n",
    "n1 = Node(\"localhost\")\n",
    "n2 = Node(\"localhost\")\n",
    "n1.start()\n",
    "n2.start()\n",
    "\n",
    "def test_multimsg2():\n",
    "\n",
    "    # Conexión\n",
    "    n1.connect_to(n2.host,n2.port)\n",
    "    time.sleep(0.1) \n",
    "\n",
    "    # Parametrizar num errores x nodo -> actualmente esta en 1 -> casque\n",
    "    n1.broadcast(b\"saludos Enrique y Dani\")\n",
    "    time.sleep(0.1) \n",
    "    #assert len(n2.neightboors) == 0\n",
    "    \n",
    "test_multimsg2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffab868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
