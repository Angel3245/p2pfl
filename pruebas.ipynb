{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3333e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 54000 Val:6000 Test:10000\n",
      "INFO:root:Nodo a la escucha en 127.0.0.1 57357\n",
      "Train: 54000 Val:6000 Test:10000\n",
      "INFO:root:Nodo a la escucha en 127.0.0.1 60853\n",
      "INFO:root:(('127.0.0.1', 57357)) Conexi√≥n aceptada con ('127.0.0.1', 60853)\n",
      "INFO:root:(('127.0.0.1', 57357)) Broadcasting start learning...\n",
      "INFO:root:(('127.0.0.1', 57357)) Sending Initial Model Weights\n",
      "INFO:root:(('127.0.0.1', 60853)) Broadcasting Number of Samples...\n",
      "INFO:root:(('127.0.0.1', 57357)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(('127.0.0.1', 60853)) Initialicing Model Weights\n",
      "INFO:root:(('127.0.0.1', 60853)) Model initialized\n",
      "INFO:root:(('127.0.0.1', 57357)) Broadcasting Number of Samples...\n",
      "INFO:root:(('127.0.0.1', 57357)) Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eec80e601784bf19276b66ab9928bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:(('127.0.0.1', 60853)) Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be82564f7414fe190e6220d1f98f18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/.local/share/virtualenvs/federated_learning_p2p-ODhT9q3L/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric Accuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:(('127.0.0.1', 60853)) Broadcasting metrics to 1 clients.\n",
      "INFO:root:(('127.0.0.1', 60853)) Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type     | Params\n",
      "------------------------------------\n",
      "0 | metric | Accuracy | 0     \n",
      "1 | l1     | Linear   | 100 K \n",
      "2 | l2     | Linear   | 33.0 K\n",
      "3 | l3     | Linear   | 2.6 K \n",
      "------------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n",
      "0.544     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIN HACERR!!\n",
      "True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:(('127.0.0.1', 57357)) Broadcasting metrics to 1 clients.\n",
      "INFO:root:(('127.0.0.1', 57357)) Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type     | Params\n",
      "------------------------------------\n",
      "0 | metric | Accuracy | 0     \n",
      "1 | l1     | Linear   | 100 K \n",
      "2 | l2     | Linear   | 33.0 K\n",
      "3 | l3     | Linear   | 2.6 K \n",
      "------------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n",
      "0.544     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIN HACERR!!\n",
      "True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aba2174bf20415b8de633f3aebf4da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50df0ed698564ce98437110fb06c2889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:(127.0.0.1:60853) Model added (1/2) from ('127.0.0.1', 60853)\n",
      "INFO:root:(('127.0.0.1', 60853)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(127.0.0.1:57357) Model added (1/2) from ('127.0.0.1', 60853)\n",
      "INFO:root:(127.0.0.1:57357) Model added (2/2) from ('127.0.0.1', 57357)\n",
      "INFO:root:(127.0.0.1:57357) Agregating models.\n",
      "INFO:root:(('127.0.0.1', 57357)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(('127.0.0.1', 57357)) Waiting other nodes.\n",
      "INFO:root:(127.0.0.1:60853) Model added (2/2) from ('127.0.0.1', 57357)\n",
      "INFO:root:(127.0.0.1:60853) Agregating models.\n",
      "INFO:root:(('127.0.0.1', 60853)) Waiting other nodes.\n",
      "INFO:root:(('127.0.0.1', 57357)) Round 1 of 2 finished.\n",
      "INFO:root:(('127.0.0.1', 60853)) Round 1 of 2 finished.\n",
      "INFO:root:(('127.0.0.1', 57357)) Evaluating...\n",
      "INFO:root:(('127.0.0.1', 60853)) Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "GPU available: False, used: False\n",
      "IPU available: False, using: 0 IPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "228963e01e564d50b476bf93ee6a592a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68cdd3e38f24749ad5c97a0c849b512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:(('127.0.0.1', 57357)) Broadcasting metrics to 1 clients.\n",
      "INFO:root:(('127.0.0.1', 57357)) Training...\n",
      "SIN HACERR!!\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type     | Params\n",
      "------------------------------------\n",
      "0 | metric | Accuracy | 0     \n",
      "1 | l1     | Linear   | 100 K \n",
      "2 | l2     | Linear   | 33.0 K\n",
      "3 | l3     | Linear   | 2.6 K \n",
      "------------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n",
      "0.544     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:(('127.0.0.1', 60853)) Broadcasting metrics to 1 clients.\n",
      "INFO:root:(('127.0.0.1', 60853)) Training...\n",
      "SIN HACERR!!\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name   | Type     | Params\n",
      "------------------------------------\n",
      "0 | metric | Accuracy | 0     \n",
      "1 | l1     | Linear   | 100 K \n",
      "2 | l2     | Linear   | 33.0 K\n",
      "3 | l3     | Linear   | 2.6 K \n",
      "------------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n",
      "0.544     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07da9de788ce40ecb80b7be90b0e9ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9ae1bfee9b4f9aa29e434f06398999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:(127.0.0.1:60853) Model added (1/2) from ('127.0.0.1', 60853)\n",
      "INFO:root:(('127.0.0.1', 60853)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(127.0.0.1:57357) Model added (1/2) from ('127.0.0.1', 60853)\n",
      "INFO:root:(127.0.0.1:57357) Model added (2/2) from ('127.0.0.1', 57357)\n",
      "INFO:root:(127.0.0.1:57357) Agregating models.\n",
      "INFO:root:(('127.0.0.1', 57357)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(('127.0.0.1', 57357)) Waiting other nodes.\n",
      "INFO:root:(127.0.0.1:60853) Model added (2/2) from ('127.0.0.1', 57357)\n",
      "INFO:root:(127.0.0.1:60853) Agregating models.\n",
      "INFO:root:(('127.0.0.1', 60853)) Waiting other nodes.\n",
      "INFO:root:(('127.0.0.1', 57357)) Round 2 of 2 finished.\n",
      "INFO:root:(('127.0.0.1', 60853)) Round 2 of 2 finished.\n",
      "INFO:root:(('127.0.0.1', 57357)) Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:(('127.0.0.1', 60853)) Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "GPU available: False, used: False\n",
      "IPU available: False, using: 0 IPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca0784fef2146d79b27ad204d4099f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed45784f07334123915659586e7e160b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:(('127.0.0.1', 60853)) Broadcasting metrics to 1 clients.\n",
      "INFO:root:(('127.0.0.1', 60853)) Finish!!.\n",
      "SIN HACERR!!\n",
      "True\n",
      "INFO:root:(('127.0.0.1', 57357)) Broadcasting metrics to 1 clients.\n",
      "INFO:root:(('127.0.0.1', 57357)) Finish!!.\n",
      "SIN HACERR!!\n",
      "True\n",
      "INFO:root:Bajando el nodo, dejando de escuchar en 127.0.0.1 57357 y desconect√°ndose de 1 nodos\n",
      "DEBUG:root:Closed connection: ('127.0.0.1', 57357)\n",
      "DEBUG:root:Closed connection: ('127.0.0.1', 60853)\n",
      "INFO:root:Bajando el nodo, dejando de escuchar en 127.0.0.1 60853 y desconect√°ndose de 0 nodos\n"
     ]
    }
   ],
   "source": [
    "from p2pfl.node import Node\n",
    "from p2pfl.learning.pytorch.mnist_examples.mnistfederated_dm import MnistFederatedDM\n",
    "from p2pfl.learning.pytorch.mnist_examples.models.mlp import MLP\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import time\n",
    "\n",
    "def test_convergence(x):\n",
    "    n,r = x\n",
    "\n",
    "    # Node Creation\n",
    "    nodes = []\n",
    "    for i in range(n):\n",
    "        node = Node(MLP(),MnistFederatedDM())\n",
    "        node.start()\n",
    "        nodes.append(node)\n",
    "\n",
    "    # Node Connection\n",
    "    for i in range(len(nodes)-1):\n",
    "        nodes[i+1].connect_to(nodes[i].host,nodes[i].port)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    # Check if they are connected\n",
    "    for node in nodes:\n",
    "        assert len(node.neightboors) == n-1\n",
    "\n",
    "    # Start Learning\n",
    "    nodes[0].set_start_learning(rounds=r,epochs=1)\n",
    "\n",
    "    # Wait 4 results\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "        finish = True\n",
    "        for f in [node.round is None for node in nodes]:\n",
    "            finish = finish and f\n",
    "\n",
    "        if finish:\n",
    "            break\n",
    "\n",
    "\n",
    "    # Validamos Modelos obtenidos sean iguales\n",
    "    model = None\n",
    "    first = True\n",
    "    for node in nodes:\n",
    "        if first:\n",
    "            model = node.learner.get_parameters()\n",
    "            first = False\n",
    "        else:\n",
    "            for layer in model:\n",
    "                a = torch.round(model[layer], decimals=2)\n",
    "                b = torch.round(node.learner.get_parameters()[layer], decimals=2)\n",
    "                assert torch.eq(a, b).all()\n",
    "\n",
    "    # Cerrar\n",
    "    for node in nodes:\n",
    "        node.stop()\n",
    "        time.sleep(.1) #Esperar por la asincron√≠a\n",
    "    \n",
    "    return nodes\n",
    "        \n",
    "nodes = test_convergence((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034fde84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from p2pfl.learning.pytorch.mnist_examples.mnistfederated_dm import MnistFederatedDM\n",
    "from p2pfl.learning.pytorch.mnist_examples.models.cnn import CNN\n",
    "from p2pfl.learning.pytorch.mnist_examples.models.mlp import MLP\n",
    "from p2pfl.node import Node\n",
    "import pytest\n",
    "import time\n",
    "import threading\n",
    "\n",
    "nodes = []\n",
    "        \n",
    "def test_node_down_on_learning(n):\n",
    "\n",
    "    # Node Creation\n",
    "    nodes = []\n",
    "    for i in range(n):\n",
    "        node = Node(MLP(),MnistFederatedDM())\n",
    "        node.start()\n",
    "        nodes.append(node)\n",
    "\n",
    "    # Node Connection\n",
    "    for i in range(len(nodes)-1):\n",
    "        nodes[i+1].connect_to(nodes[i].host,nodes[i].port)\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Check if they are connected\n",
    "    for node in nodes:\n",
    "        assert len(node.neightboors) == n-1\n",
    "\n",
    "    # Start Learning\n",
    "    nodes[0].set_start_learning(rounds=2,epochs=0)\n",
    "\n",
    "    # Stopping node\n",
    "    nodes[1].stop()\n",
    "    # Wait 4 results\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "        finish = True\n",
    "        for f in [node.round is None for node in nodes]:\n",
    "            finish = finish and f\n",
    "\n",
    "        if finish:\n",
    "            break\n",
    "\n",
    "    for node in nodes:\n",
    "        node.stop()\n",
    "\n",
    "\n",
    "nodes = []\n",
    "for _ in range(6):\n",
    "    test_node_down_on_learning(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d86781",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainThread\n",
      "IOPub\n",
      "Heartbeat\n",
      "Thread-3\n",
      "Thread-4\n",
      "Control\n",
      "IPythonHistorySavingThread\n",
      "Thread-2\n"
     ]
    }
   ],
   "source": [
    "#import threading\n",
    "for thread in threading.enumerate(): \n",
    "    print(thread.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "445e009c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/pedro/Documents/UDC/4/TFG/federated_learning_p2p/p2pfl/node.py',\n",
       " '__on_round_finished',\n",
       " 260)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def get_thread_position(thread):\n",
    "    frame = sys._current_frames().get(thread.ident, None)\n",
    "    if frame:\n",
    "        return frame.f_code.co_filename, frame.f_code.co_name, frame.f_code.co_firstlineno\n",
    "\n",
    "get_thread_position(threading.enumerate()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4471063f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainThread\n",
      "IOPub\n",
      "Heartbeat\n",
      "Thread-3\n",
      "Thread-4\n",
      "Control\n",
      "IPythonHistorySavingThread\n",
      "Thread-2\n",
      "Train: 54000 Val:6000 Test:10000\n",
      "Train: 54000 Val:6000 Test:10000\n",
      "\n",
      "\n",
      "INFO:root:Nodo a la escucha en 127.0.0.1 54998\n",
      "INFO:root:Nodo a la escucha en 127.0.0.1 54999\n",
      "INFO:root:(('127.0.0.1', 54999)) Conexi√≥n aceptada con ('127.0.0.1', 54998)\n",
      "INFO:root:(('127.0.0.1', 54998)) Broadcasting start learning...\n",
      "INFO:root:(('127.0.0.1', 54998)) Sending Initial Model Weights\n",
      "INFO:root:(('127.0.0.1', 54999)) Initialicing Model Weights\n",
      "INFO:root:(('127.0.0.1', 54998)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(('127.0.0.1', 54998)) Broadcasting Number of Samples...\n",
      "INFO:root:(('127.0.0.1', 54998)) Training...\n",
      "INFO:root:(('127.0.0.1', 54999)) Model initialized\n",
      "INFO:root:(('127.0.0.1', 54998)) Model added (1/2) from ('127.0.0.1', 54998)\n",
      "INFO:root:(('127.0.0.1', 54998)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(('127.0.0.1', 54999)) Model added (1/2) from ('127.0.0.1', 54998)\n",
      "INFO:root:(('127.0.0.1', 54999)) Broadcasting Number of Samples...\n",
      "INFO:root:(('127.0.0.1', 54999)) Training...\n",
      "INFO:root:(('127.0.0.1', 54999)) Model added (2/2) from ('127.0.0.1', 54999)\n",
      "INFO:root:(('127.0.0.1', 54999)) Agregating models.\n",
      "INFO:root:(('127.0.0.1', 54999)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(('127.0.0.1', 54999)) Waiting other nodes.\n",
      "ERROR:root:(('127.0.0.1', 54998)) Error decoding parameters\n",
      "INFO:root:(('127.0.0.1', 54998)) Stopping learning\n",
      "INFO:root:Bajando el nodo, dejando de escuchar en 127.0.0.1 54998 y desconect√°ndose de 1 nodos\n",
      "DEBUG:root:Closed connection: ('127.0.0.1', 54998)\n",
      "DEBUG:root:Closed connection: ('127.0.0.1', 54999)\n",
      "INFO:root:(('127.0.0.1', 54999)) Stopping learning\n",
      "INFO:root:Bajando el nodo, dejando de escuchar en 127.0.0.1 54999 y desconect√°ndose de 0 nodos\n",
      "MainThread\n",
      "IOPub\n",
      "Heartbeat\n",
      "Thread-3\n",
      "Thread-4\n",
      "Control\n",
      "IPythonHistorySavingThread\n",
      "Thread-2\n",
      "heartbeater-127.0.0.1:54999\n",
      "node-127.0.0.1:54999\n",
      "learning_thread-127.0.0.1:54999\n",
      "learning_thread-127.0.0.1:54998\n",
      "agregator-127.0.0.1:54998\n",
      "\n",
      "\n",
      "INFO:root:(('127.0.0.1', 54999)) Stopping on_round_finished process.\n"
     ]
    }
   ],
   "source": [
    "from p2pfl.const import HEARTBEAT_FREC, SOCKET_TIEMOUT\n",
    "from p2pfl.learning.pytorch.mnist_examples.mnistfederated_dm import MnistFederatedDM\n",
    "from p2pfl.learning.pytorch.mnist_examples.models.cnn import CNN\n",
    "from p2pfl.learning.pytorch.mnist_examples.models.mlp import MLP\n",
    "from p2pfl.node import Node\n",
    "import pytest\n",
    "import time\n",
    "from test.fixtures import two_nodes, four_nodes\n",
    "\n",
    "\n",
    "import threading\n",
    "for thread in threading.enumerate(): \n",
    "    print(thread.name)\n",
    "    \n",
    "n1 = Node(MLP(),MnistFederatedDM())\n",
    "n2 = Node(MLP(),MnistFederatedDM())\n",
    "print(\"\\n\")\n",
    "def test_bad_binary_model():\n",
    "\n",
    "    n1.start()\n",
    "    n2.start()\n",
    "\n",
    "    n1.connect_to(n2.host,n2.port)\n",
    "    time.sleep(0.1) \n",
    "\n",
    "    # Start Learning\n",
    "    n1.set_start_learning(rounds=2,epochs=0)\n",
    " \n",
    "    # Adding noise to the buffer\n",
    "    for _ in range(200):\n",
    "        n1.neightboors[0].param_bufffer += \"noise\".encode(\"utf-8\")\n",
    "    \n",
    "    while not n1.round is None and not n2.round is None:\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "    n1.stop()\n",
    "    n2.stop()\n",
    "    \n",
    "test_bad_binary_model()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "for thread in threading.enumerate(): \n",
    "    print(thread.name)\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7fe91dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainThread\n",
      "IOPub\n",
      "Heartbeat\n",
      "Thread-3\n",
      "Thread-4\n",
      "Control\n",
      "IPythonHistorySavingThread\n",
      "Thread-2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for thread in threading.enumerate(): \n",
    "    print(thread.name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aec30564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(n1.round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc69eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from p2pfl.settings import Settings\n",
    "\n",
    "Settings.AGREGATION_TIEMOUT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccd4109a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"0.1545318067073822\".isdecimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cfda0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.301456928253174 0.13700607419013977\n"
     ]
    }
   ],
   "source": [
    "message = ['METRICS', '0', '2.301456928253174', '0.13700607419013977']\n",
    "print(int(message[1]), float(message[2]), float(message[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bf3c79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
