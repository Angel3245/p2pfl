{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de3333e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 54000 Val:6000 Test:10000\n",
      "INFO:root:Nodo a la escucha en 127.0.0.1 48281\n",
      "Train: 54000 Val:6000 Test:10000\n",
      "INFO:root:Nodo a la escucha en 127.0.0.1 53389\n",
      "INFO:root:(('127.0.0.1', 48281)) Conexión aceptada con ('127.0.0.1', 53389)\n",
      "INFO:root:(('127.0.0.1', 48281)) Broadcasting start learning...\n",
      "INFO:root:(('127.0.0.1', 48281)) Sending Initial Model Weights\n",
      "INFO:root:(('127.0.0.1', 53389)) Broadcasting Number of Samples...\n",
      "INFO:root:(('127.0.0.1', 53389)) Initialicing Model Weights\n",
      "INFO:root:(('127.0.0.1', 48281)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(('127.0.0.1', 48281)) Broadcasting Number of Samples...\n",
      "INFO:root:(('127.0.0.1', 53389)) Model initialized\n",
      "INFO:root:(('127.0.0.1', 48281)) Training...\n",
      "INFO:root:(127.0.0.1:48281) Model added (1/2) from ('127.0.0.1', 48281)\n",
      "INFO:root:(('127.0.0.1', 48281)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(127.0.0.1:53389) Model added (1/2) from ('127.0.0.1', 48281)\n",
      "INFO:root:(('127.0.0.1', 53389)) Training...\n",
      "INFO:root:(127.0.0.1:53389) Model added (2/2) from ('127.0.0.1', 53389)\n",
      "INFO:root:(127.0.0.1:53389) Agregating models.\n",
      "INFO:root:(('127.0.0.1', 53389)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(('127.0.0.1', 53389)) Waiting other nodes.\n",
      "INFO:root:(127.0.0.1:48281) Model added (2/2) from ('127.0.0.1', 53389)\n",
      "INFO:root:(127.0.0.1:48281) Agregating models.\n",
      "INFO:root:(('127.0.0.1', 48281)) Waiting other nodes.\n",
      "INFO:root:(('127.0.0.1', 53389)) Evaluating...\n",
      "INFO:root:(('127.0.0.1', 48281)) Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "GPU available: False, used: False\n",
      "IPU available: False, using: 0 IPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56be8ccfd77c4249bc2468a2de48d272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd3ce6d2e354e30bd276eace3f53c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            2.301456928253174\n",
      "       test_metric          0.2083991914987564\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "(2.301456928253174, 0.2083991914987564)\n",
      "INFO:root:(('127.0.0.1', 53389)) Broadcasting metrics to 1 clients.\n",
      "INFO:root:(('127.0.0.1', 53389)) Round 1 of 2 finished.\n",
      "SIN HACERR!!\n",
      "INFO:root:(('127.0.0.1', 53389)) Training...\n",
      "INFO:root:(127.0.0.1:53389) Model added (1/2) from ('127.0.0.1', 53389)\n",
      "INFO:root:(('127.0.0.1', 53389)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(127.0.0.1:48281) Model added (1/2) from ('127.0.0.1', 53389)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            2.301456928253174\n",
      "       test_metric          0.14995156228542328\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "(2.301456928253174, 0.14995156228542328)\n",
      "INFO:root:(('127.0.0.1', 48281)) Broadcasting metrics to 1 clients.\n",
      "INFO:root:(('127.0.0.1', 48281)) Round 1 of 2 finished.\n",
      "SIN HACERR!!\n",
      "INFO:root:(('127.0.0.1', 48281)) Training...\n",
      "INFO:root:(127.0.0.1:48281) Model added (2/2) from ('127.0.0.1', 48281)\n",
      "INFO:root:(127.0.0.1:48281) Agregating models.\n",
      "INFO:root:(('127.0.0.1', 48281)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(('127.0.0.1', 48281)) Waiting other nodes.\n",
      "INFO:root:(127.0.0.1:53389) Model added (2/2) from ('127.0.0.1', 48281)\n",
      "INFO:root:(127.0.0.1:53389) Agregating models.\n",
      "INFO:root:(('127.0.0.1', 53389)) Waiting other nodes.\n",
      "INFO:root:(('127.0.0.1', 48281)) Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:(('127.0.0.1', 53389)) Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "GPU available: False, used: False\n",
      "IPU available: False, using: 0 IPUs\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2060078f25c34d1fb06af84a465117a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9fef93b52242fa969aa76858fe05e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            2.301456928253174\n",
      "       test_metric          0.14519190788269043\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "(2.301456928253174, 0.14519190788269043)\n",
      "INFO:root:(('127.0.0.1', 53389)) Broadcasting metrics to 1 clients.\n",
      "SIN HACERR!!INFO:root:(('127.0.0.1', 53389)) Round 2 of 2 finished.\n",
      "\n",
      "INFO:root:(('127.0.0.1', 53389)) Finish!!.\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            2.301456928253174\n",
      "       test_metric          0.13697433471679688\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "(2.301456928253174, 0.13697433471679688)\n",
      "INFO:root:(('127.0.0.1', 48281)) Broadcasting metrics to 1 clients.\n",
      "INFO:root:(('127.0.0.1', 48281)) Round 2 of 2 finished.\n",
      "INFO:root:(('127.0.0.1', 48281)) Finish!!.\n",
      "SIN HACERR!!\n",
      "INFO:root:Bajando el nodo, dejando de escuchar en 127.0.0.1 48281 y desconectándose de 1 nodos\n",
      "DEBUG:root:Closed connection: ('127.0.0.1', 48281)\n",
      "DEBUG:root:Closed connection: ('127.0.0.1', 53389)\n",
      "INFO:root:Bajando el nodo, dejando de escuchar en 127.0.0.1 53389 y desconectándose de 0 nodos\n"
     ]
    }
   ],
   "source": [
    "from p2pfl.node import Node\n",
    "from p2pfl.learning.pytorch.mnist_examples.mnistfederated_dm import MnistFederatedDM\n",
    "from p2pfl.learning.pytorch.mnist_examples.models.mlp import MLP\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import time\n",
    "\n",
    "def test_convergence(x):\n",
    "    n,r = x\n",
    "\n",
    "    # Node Creation\n",
    "    nodes = []\n",
    "    for i in range(n):\n",
    "        node = Node(MLP(),MnistFederatedDM())\n",
    "        node.start()\n",
    "        nodes.append(node)\n",
    "\n",
    "    # Node Connection\n",
    "    for i in range(len(nodes)-1):\n",
    "        nodes[i+1].connect_to(nodes[i].host,nodes[i].port)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    # Check if they are connected\n",
    "    for node in nodes:\n",
    "        assert len(node.neightboors) == n-1\n",
    "\n",
    "    # Start Learning\n",
    "    nodes[0].set_start_learning(rounds=r,epochs=0)\n",
    "\n",
    "    # Wait 4 results\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "        finish = True\n",
    "        for f in [node.round is None for node in nodes]:\n",
    "            finish = finish and f\n",
    "\n",
    "        if finish:\n",
    "            break\n",
    "\n",
    "\n",
    "    # Validamos Modelos obtenidos sean iguales\n",
    "    model = None\n",
    "    first = True\n",
    "    for node in nodes:\n",
    "        if first:\n",
    "            model = node.learner.get_parameters()\n",
    "            first = False\n",
    "        else:\n",
    "            for layer in model:\n",
    "                a = torch.round(model[layer], decimals=2)\n",
    "                b = torch.round(node.learner.get_parameters()[layer], decimals=2)\n",
    "                assert torch.eq(a, b).all()\n",
    "\n",
    "    # Cerrar\n",
    "    for node in nodes:\n",
    "        node.stop()\n",
    "        time.sleep(.1) #Esperar por la asincronía\n",
    "    \n",
    "    return nodes\n",
    "        \n",
    "nodes = test_convergence((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034fde84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from p2pfl.learning.pytorch.mnist_examples.mnistfederated_dm import MnistFederatedDM\n",
    "from p2pfl.learning.pytorch.mnist_examples.models.cnn import CNN\n",
    "from p2pfl.learning.pytorch.mnist_examples.models.mlp import MLP\n",
    "from p2pfl.node import Node\n",
    "import pytest\n",
    "import time\n",
    "import threading\n",
    "\n",
    "nodes = []\n",
    "        \n",
    "def test_node_down_on_learning(n):\n",
    "\n",
    "    # Node Creation\n",
    "    nodes = []\n",
    "    for i in range(n):\n",
    "        node = Node(MLP(),MnistFederatedDM())\n",
    "        node.start()\n",
    "        nodes.append(node)\n",
    "\n",
    "    # Node Connection\n",
    "    for i in range(len(nodes)-1):\n",
    "        nodes[i+1].connect_to(nodes[i].host,nodes[i].port)\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Check if they are connected\n",
    "    for node in nodes:\n",
    "        assert len(node.neightboors) == n-1\n",
    "\n",
    "    # Start Learning\n",
    "    nodes[0].set_start_learning(rounds=2,epochs=0)\n",
    "\n",
    "    # Stopping node\n",
    "    nodes[1].stop()\n",
    "    # Wait 4 results\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "        finish = True\n",
    "        for f in [node.round is None for node in nodes]:\n",
    "            finish = finish and f\n",
    "\n",
    "        if finish:\n",
    "            break\n",
    "\n",
    "    for node in nodes:\n",
    "        node.stop()\n",
    "\n",
    "\n",
    "nodes = []\n",
    "for _ in range(6):\n",
    "    test_node_down_on_learning(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d86781",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainThread\n",
      "IOPub\n",
      "Heartbeat\n",
      "Thread-3\n",
      "Thread-4\n",
      "Control\n",
      "IPythonHistorySavingThread\n",
      "Thread-2\n"
     ]
    }
   ],
   "source": [
    "#import threading\n",
    "for thread in threading.enumerate(): \n",
    "    print(thread.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "445e009c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/pedro/Documents/UDC/4/TFG/federated_learning_p2p/p2pfl/node.py',\n",
       " '__on_round_finished',\n",
       " 260)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def get_thread_position(thread):\n",
    "    frame = sys._current_frames().get(thread.ident, None)\n",
    "    if frame:\n",
    "        return frame.f_code.co_filename, frame.f_code.co_name, frame.f_code.co_firstlineno\n",
    "\n",
    "get_thread_position(threading.enumerate()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4471063f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainThread\n",
      "IOPub\n",
      "Heartbeat\n",
      "Thread-3\n",
      "Thread-4\n",
      "Control\n",
      "IPythonHistorySavingThread\n",
      "Thread-2\n",
      "Train: 54000 Val:6000 Test:10000\n",
      "Train: 54000 Val:6000 Test:10000\n",
      "\n",
      "\n",
      "INFO:root:Nodo a la escucha en 127.0.0.1 54998\n",
      "INFO:root:Nodo a la escucha en 127.0.0.1 54999\n",
      "INFO:root:(('127.0.0.1', 54999)) Conexión aceptada con ('127.0.0.1', 54998)\n",
      "INFO:root:(('127.0.0.1', 54998)) Broadcasting start learning...\n",
      "INFO:root:(('127.0.0.1', 54998)) Sending Initial Model Weights\n",
      "INFO:root:(('127.0.0.1', 54999)) Initialicing Model Weights\n",
      "INFO:root:(('127.0.0.1', 54998)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(('127.0.0.1', 54998)) Broadcasting Number of Samples...\n",
      "INFO:root:(('127.0.0.1', 54998)) Training...\n",
      "INFO:root:(('127.0.0.1', 54999)) Model initialized\n",
      "INFO:root:(('127.0.0.1', 54998)) Model added (1/2) from ('127.0.0.1', 54998)\n",
      "INFO:root:(('127.0.0.1', 54998)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(('127.0.0.1', 54999)) Model added (1/2) from ('127.0.0.1', 54998)\n",
      "INFO:root:(('127.0.0.1', 54999)) Broadcasting Number of Samples...\n",
      "INFO:root:(('127.0.0.1', 54999)) Training...\n",
      "INFO:root:(('127.0.0.1', 54999)) Model added (2/2) from ('127.0.0.1', 54999)\n",
      "INFO:root:(('127.0.0.1', 54999)) Agregating models.\n",
      "INFO:root:(('127.0.0.1', 54999)) Broadcasting model to 1 clients. (size: 548864 bytes)\n",
      "INFO:root:(('127.0.0.1', 54999)) Waiting other nodes.\n",
      "ERROR:root:(('127.0.0.1', 54998)) Error decoding parameters\n",
      "INFO:root:(('127.0.0.1', 54998)) Stopping learning\n",
      "INFO:root:Bajando el nodo, dejando de escuchar en 127.0.0.1 54998 y desconectándose de 1 nodos\n",
      "DEBUG:root:Closed connection: ('127.0.0.1', 54998)\n",
      "DEBUG:root:Closed connection: ('127.0.0.1', 54999)\n",
      "INFO:root:(('127.0.0.1', 54999)) Stopping learning\n",
      "INFO:root:Bajando el nodo, dejando de escuchar en 127.0.0.1 54999 y desconectándose de 0 nodos\n",
      "MainThread\n",
      "IOPub\n",
      "Heartbeat\n",
      "Thread-3\n",
      "Thread-4\n",
      "Control\n",
      "IPythonHistorySavingThread\n",
      "Thread-2\n",
      "heartbeater-127.0.0.1:54999\n",
      "node-127.0.0.1:54999\n",
      "learning_thread-127.0.0.1:54999\n",
      "learning_thread-127.0.0.1:54998\n",
      "agregator-127.0.0.1:54998\n",
      "\n",
      "\n",
      "INFO:root:(('127.0.0.1', 54999)) Stopping on_round_finished process.\n"
     ]
    }
   ],
   "source": [
    "from p2pfl.const import HEARTBEAT_FREC, SOCKET_TIEMOUT\n",
    "from p2pfl.learning.pytorch.mnist_examples.mnistfederated_dm import MnistFederatedDM\n",
    "from p2pfl.learning.pytorch.mnist_examples.models.cnn import CNN\n",
    "from p2pfl.learning.pytorch.mnist_examples.models.mlp import MLP\n",
    "from p2pfl.node import Node\n",
    "import pytest\n",
    "import time\n",
    "from test.fixtures import two_nodes, four_nodes\n",
    "\n",
    "\n",
    "import threading\n",
    "for thread in threading.enumerate(): \n",
    "    print(thread.name)\n",
    "    \n",
    "n1 = Node(MLP(),MnistFederatedDM())\n",
    "n2 = Node(MLP(),MnistFederatedDM())\n",
    "print(\"\\n\")\n",
    "def test_bad_binary_model():\n",
    "\n",
    "    n1.start()\n",
    "    n2.start()\n",
    "\n",
    "    n1.connect_to(n2.host,n2.port)\n",
    "    time.sleep(0.1) \n",
    "\n",
    "    # Start Learning\n",
    "    n1.set_start_learning(rounds=2,epochs=0)\n",
    " \n",
    "    # Adding noise to the buffer\n",
    "    for _ in range(200):\n",
    "        n1.neightboors[0].param_bufffer += \"noise\".encode(\"utf-8\")\n",
    "    \n",
    "    while not n1.round is None and not n2.round is None:\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "    n1.stop()\n",
    "    n2.stop()\n",
    "    \n",
    "test_bad_binary_model()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "for thread in threading.enumerate(): \n",
    "    print(thread.name)\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7fe91dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainThread\n",
      "IOPub\n",
      "Heartbeat\n",
      "Thread-3\n",
      "Thread-4\n",
      "Control\n",
      "IPythonHistorySavingThread\n",
      "Thread-2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for thread in threading.enumerate(): \n",
    "    print(thread.name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aec30564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(n1.round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc69eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from p2pfl.settings import Settings\n",
    "\n",
    "Settings.AGREGATION_TIEMOUT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccd4109a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"0.1545318067073822\".isdecimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfda0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
